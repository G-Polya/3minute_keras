{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "import keras\n",
    "assert keras.backend.image_data_format()  == 'channels_last'\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "\n",
    "from keraspp.skeras import *\n",
    "from keraspp.sfile import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Model):\n",
    "    def __init__(model, nb_classes, in_shape=None):\n",
    "        model.nb_classes = nb_classes\n",
    "        model.in_shape = in_shape\n",
    "        model.build_model()\n",
    "        super().__init__(model.x, model.y)\n",
    "        model.compile()\n",
    "        \n",
    "    def build_model(model):\n",
    "        nb_classes = model.nb_classes\n",
    "        in_shape = model.in_shape\n",
    "        \n",
    "        x = Input(in_shape)\n",
    "        h = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\n",
    "        h = Conv2D(64,(3,3),activation='relu')(h)\n",
    "        h = MaxPooling2D(pool_size=(2,2))(h)\n",
    "        h = Dropout(0.25)(h)\n",
    "        h = Flatten()(h)\n",
    "        z_cl = h\n",
    "        \n",
    "        h = Dense(128, activation='relu')(h)\n",
    "        h = Dropout(0.5)(h)\n",
    "        z_fl = h\n",
    "        \n",
    "        y = Dense(nb_classes, activation='softmax', name='preds')(h)\n",
    "        \n",
    "#         model.cl_part = Model(x,z_cl)\n",
    "#         model.fl_part = Model(x,z_fl)\n",
    "        \n",
    "        model.x, model.y = x,y\n",
    "        \n",
    "    def compile(model):\n",
    "        Model.compile(model, loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self,X,y,nb_classes, scaling=True, test_size=0.2, random_state=0):\n",
    "        self.X = X\n",
    "        self.add_channels()\n",
    "        \n",
    "        X = self.X\n",
    "        X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=0.2,random_state=random_state)\n",
    "        \n",
    "        print(X_train.shape,y_train.shape)\n",
    "        \n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        \n",
    "        if scaling:\n",
    "            scaler = MinMaxScaler()\n",
    "            n = X_train.shape[0]\n",
    "            X_train = scaler.fit_transform(X_train.reshape(n,-1)).reshape(X_train.shape)\n",
    "            n = X_test.shape[0]\n",
    "            X_test = scaler.fit_transform(X_test.reshape(n,-1)).reshape(X_test.shape)\n",
    "            self.scaler = scaler\n",
    "            \n",
    "            print('X_train shape : ', X_train.shape)\n",
    "            print(X_train.shape[0], ' train samples')\n",
    "            print(X_test.shape[0], ' test samples')\n",
    "            \n",
    "            Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "            Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "            \n",
    "            self.X_train, self.X_test = X_train, X_test\n",
    "            self.Y_train, self.Y_test = Y_train, Y_test\n",
    "            self.y_train, self.y_test = y_train, y_test\n",
    "            \n",
    "    def add_channels(self):\n",
    "        X = self.X\n",
    "        \n",
    "        if len(X.shape) == 3:\n",
    "            N, img_rows, img_cols = X.shape\n",
    "            \n",
    "            if K.image_dim_ordering() == 'th':\n",
    "                X = X.reshape(X.shape[0],1,img_rows, img_cols)\n",
    "                input_shape = (1, img_rows, img_cols)\n",
    "            else:\n",
    "                X = X.reshape(X.shape[0],img_rows, img_cols, 1)\n",
    "                input_shape = (img_rows, img_cols, 1)\n",
    "        else:\n",
    "            input_shape = X.shape[1:]\n",
    "            \n",
    "        self.X = X\n",
    "        self.input_shape = input_shape\n",
    "            \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine():\n",
    "    def __init__(self,X,y,nb_classes=2,fig=True):\n",
    "        self.nb_classes = nb_classes\n",
    "        self.set_data(X,y)\n",
    "        self.set_model()\n",
    "        self.fig = fig\n",
    "        \n",
    "    def set_data(self, X,y):\n",
    "        nb_classes = self.nb_classes\n",
    "        self.data = DataSet(X,y,nb_classes)\n",
    "        print('data.input_shape ', self.data.input_shape)\n",
    "        \n",
    "    def set_model(self):\n",
    "        nb_classes = self.nb_classes\n",
    "        data = self.data\n",
    "        self.model = CNN(nb_classes=nb_classes, in_shape=data.input_shape)\n",
    "    def fit(self, epochs=10, batch_size=128, verbose=1):\n",
    "        data = self.data\n",
    "        model = self.model\n",
    "        \n",
    "        history = model.fit(data.X_train, data.Y_train, batch_size=batch_size,epochs=epochs,\n",
    "                           verbose=verbose,validation_data=(data.X_test,data.Y_test))\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def run(self, epochs=100, batch_size=128, verbose=1):\n",
    "        data = self.data\n",
    "        model = self.model\n",
    "        fig = self.fig\n",
    "        \n",
    "        history = self.fit(epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        \n",
    "        score = model.evaluate(data.X_test, data.Y_test, verbose=0)\n",
    "        \n",
    "        print('Confusion matrix')\n",
    "        Y_test_pred = model.predict(data.X_test,verbose=0)\n",
    "        y_test_pred = np.argmax(Y_test_pred,axis=1)\n",
    "        print(metrics.confusion_matrix(data.y_test, y_test_pred))\n",
    "        \n",
    "        print('Test Score: ',score[0])\n",
    "        print('Test Accuracy: ', score[1])\n",
    "        \n",
    "        suffix = unique_filename('datatime')\n",
    "        foldname = 'output_'+suffix\n",
    "        os.makedirs(foldname)\n",
    "        save_history_history('history_history.npy', history.history, fold=foldname)\n",
    "        model.save_weights(os.path.join(foldname, 'dl_model.h5'))\n",
    "        print('Output results are saved in ', foldname)\n",
    "        \n",
    "        if fig:\n",
    "            plt.figure(figsize=(12,4))\n",
    "            plt.subplot(1,2,1)\n",
    "            plot_acc(history)\n",
    "            plt.subplot(1,2,2)\n",
    "            plot_loss(history)\n",
    "            plt.show()\n",
    "        \n",
    "        self.history=history\n",
    "        return foldname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3) (40000, 1)\n",
      "X_train shape :  (40000, 32, 32, 3)\n",
      "40000  train samples\n",
      "10000  test samples\n",
      "data.input_shape  (32, 32, 3)\n",
      "Epoch 1/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.3153 - accuracy: 0.1074 - val_loss: 2.2882 - val_accuracy: 0.1355\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2987 - accuracy: 0.1165 - val_loss: 2.2764 - val_accuracy: 0.1601\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2858 - accuracy: 0.1303 - val_loss: 2.2660 - val_accuracy: 0.1733\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2775 - accuracy: 0.1378 - val_loss: 2.2561 - val_accuracy: 0.1972\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2675 - accuracy: 0.1481 - val_loss: 2.2455 - val_accuracy: 0.2173\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2575 - accuracy: 0.1613 - val_loss: 2.2344 - val_accuracy: 0.2299\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2497 - accuracy: 0.1593 - val_loss: 2.2231 - val_accuracy: 0.2236\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2385 - accuracy: 0.1700 - val_loss: 2.2114 - val_accuracy: 0.2388\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2291 - accuracy: 0.1775 - val_loss: 2.1997 - val_accuracy: 0.2501\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2200 - accuracy: 0.1800 - val_loss: 2.1875 - val_accuracy: 0.2571\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2111 - accuracy: 0.1858 - val_loss: 2.1752 - val_accuracy: 0.2677\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1984 - accuracy: 0.1934 - val_loss: 2.1623 - val_accuracy: 0.2733\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1897 - accuracy: 0.1985 - val_loss: 2.1500 - val_accuracy: 0.2746\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1795 - accuracy: 0.2026 - val_loss: 2.1378 - val_accuracy: 0.2804\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1697 - accuracy: 0.2065 - val_loss: 2.1257 - val_accuracy: 0.2823\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1615 - accuracy: 0.2091 - val_loss: 2.1141 - val_accuracy: 0.2907\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1497 - accuracy: 0.2178 - val_loss: 2.1024 - val_accuracy: 0.2983\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1419 - accuracy: 0.2232 - val_loss: 2.0912 - val_accuracy: 0.3023\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1316 - accuracy: 0.2250 - val_loss: 2.0802 - val_accuracy: 0.3043\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1236 - accuracy: 0.2281 - val_loss: 2.0702 - val_accuracy: 0.3105\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.1125 - accuracy: 0.2352 - val_loss: 2.0600 - val_accuracy: 0.3137\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.1077 - accuracy: 0.2342 - val_loss: 2.0509 - val_accuracy: 0.3127\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.0976 - accuracy: 0.2397 - val_loss: 2.0421 - val_accuracy: 0.3194\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.0911 - accuracy: 0.2430 - val_loss: 2.0337 - val_accuracy: 0.3208\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0835 - accuracy: 0.2455 - val_loss: 2.0252 - val_accuracy: 0.3231\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0787 - accuracy: 0.2456 - val_loss: 2.0177 - val_accuracy: 0.3251\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0750 - accuracy: 0.2467 - val_loss: 2.0108 - val_accuracy: 0.3266\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0650 - accuracy: 0.2522 - val_loss: 2.0035 - val_accuracy: 0.3280\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0609 - accuracy: 0.2519 - val_loss: 1.9969 - val_accuracy: 0.3302\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0531 - accuracy: 0.2573 - val_loss: 1.9905 - val_accuracy: 0.3337\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0455 - accuracy: 0.2611 - val_loss: 1.9838 - val_accuracy: 0.3325\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0419 - accuracy: 0.2613 - val_loss: 1.9771 - val_accuracy: 0.3395\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0367 - accuracy: 0.2642 - val_loss: 1.9711 - val_accuracy: 0.3371\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0316 - accuracy: 0.2661 - val_loss: 1.9652 - val_accuracy: 0.3386\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0243 - accuracy: 0.2724 - val_loss: 1.9598 - val_accuracy: 0.3410\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0204 - accuracy: 0.2739 - val_loss: 1.9538 - val_accuracy: 0.3415\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0150 - accuracy: 0.2738 - val_loss: 1.9485 - val_accuracy: 0.3412\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0092 - accuracy: 0.2797 - val_loss: 1.9432 - val_accuracy: 0.3448\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0089 - accuracy: 0.2780 - val_loss: 1.9380 - val_accuracy: 0.3436\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0041 - accuracy: 0.2785 - val_loss: 1.9336 - val_accuracy: 0.3479\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.0002 - accuracy: 0.2812 - val_loss: 1.9288 - val_accuracy: 0.3487\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9951 - accuracy: 0.2850 - val_loss: 1.9242 - val_accuracy: 0.3493\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9891 - accuracy: 0.2851 - val_loss: 1.9190 - val_accuracy: 0.3511\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9855 - accuracy: 0.2841 - val_loss: 1.9146 - val_accuracy: 0.3515\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9789 - accuracy: 0.2906 - val_loss: 1.9092 - val_accuracy: 0.3553\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9758 - accuracy: 0.2898 - val_loss: 1.9047 - val_accuracy: 0.3554\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9709 - accuracy: 0.2935 - val_loss: 1.9002 - val_accuracy: 0.3577\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9667 - accuracy: 0.2957 - val_loss: 1.8960 - val_accuracy: 0.3588\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9628 - accuracy: 0.2971 - val_loss: 1.8912 - val_accuracy: 0.3591\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9624 - accuracy: 0.2974 - val_loss: 1.8871 - val_accuracy: 0.3610\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9594 - accuracy: 0.3009 - val_loss: 1.8834 - val_accuracy: 0.3620\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9540 - accuracy: 0.3012 - val_loss: 1.8792 - val_accuracy: 0.3635\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9522 - accuracy: 0.3029 - val_loss: 1.8753 - val_accuracy: 0.3635\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9480 - accuracy: 0.3033 - val_loss: 1.8718 - val_accuracy: 0.3641\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9438 - accuracy: 0.3076 - val_loss: 1.8672 - val_accuracy: 0.3666\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9365 - accuracy: 0.3086 - val_loss: 1.8632 - val_accuracy: 0.3685\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9312 - accuracy: 0.3087 - val_loss: 1.8587 - val_accuracy: 0.3676\n",
      "Epoch 58/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9345 - accuracy: 0.3090 - val_loss: 1.8557 - val_accuracy: 0.3694\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9311 - accuracy: 0.3112 - val_loss: 1.8519 - val_accuracy: 0.3705\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9274 - accuracy: 0.3115 - val_loss: 1.8483 - val_accuracy: 0.3749\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9218 - accuracy: 0.3120 - val_loss: 1.8448 - val_accuracy: 0.3719\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.9168 - accuracy: 0.3158 - val_loss: 1.8410 - val_accuracy: 0.3755\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9126 - accuracy: 0.3165 - val_loss: 1.8366 - val_accuracy: 0.3785\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9126 - accuracy: 0.3169 - val_loss: 1.8335 - val_accuracy: 0.3762\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9090 - accuracy: 0.3189 - val_loss: 1.8303 - val_accuracy: 0.3791\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9061 - accuracy: 0.3218 - val_loss: 1.8269 - val_accuracy: 0.3783\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9034 - accuracy: 0.3199 - val_loss: 1.8238 - val_accuracy: 0.3805\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9018 - accuracy: 0.3252 - val_loss: 1.8205 - val_accuracy: 0.3819\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8983 - accuracy: 0.3268 - val_loss: 1.8171 - val_accuracy: 0.3822\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8947 - accuracy: 0.3266 - val_loss: 1.8138 - val_accuracy: 0.3821\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8904 - accuracy: 0.3272 - val_loss: 1.8105 - val_accuracy: 0.3841\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8905 - accuracy: 0.3262 - val_loss: 1.8075 - val_accuracy: 0.3856\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8885 - accuracy: 0.3263 - val_loss: 1.8047 - val_accuracy: 0.3859\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8826 - accuracy: 0.3305 - val_loss: 1.8008 - val_accuracy: 0.3880\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8825 - accuracy: 0.3293 - val_loss: 1.7981 - val_accuracy: 0.3885\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8756 - accuracy: 0.3334 - val_loss: 1.7946 - val_accuracy: 0.3888\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8740 - accuracy: 0.3321 - val_loss: 1.7918 - val_accuracy: 0.3899\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8745 - accuracy: 0.3332 - val_loss: 1.7892 - val_accuracy: 0.3921\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8643 - accuracy: 0.3390 - val_loss: 1.7859 - val_accuracy: 0.3926\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8652 - accuracy: 0.3392 - val_loss: 1.7829 - val_accuracy: 0.3916\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8625 - accuracy: 0.3384 - val_loss: 1.7804 - val_accuracy: 0.3923\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8618 - accuracy: 0.3395 - val_loss: 1.7780 - val_accuracy: 0.3952\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8551 - accuracy: 0.3433 - val_loss: 1.7743 - val_accuracy: 0.3965\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8577 - accuracy: 0.3390 - val_loss: 1.7720 - val_accuracy: 0.3958\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8526 - accuracy: 0.3402 - val_loss: 1.7696 - val_accuracy: 0.3968\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8503 - accuracy: 0.3428 - val_loss: 1.7667 - val_accuracy: 0.3975\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8476 - accuracy: 0.3423 - val_loss: 1.7640 - val_accuracy: 0.3985\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.8420 - accuracy: 0.3457 - val_loss: 1.7610 - val_accuracy: 0.3989\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.8426 - accuracy: 0.3456 - val_loss: 1.7587 - val_accuracy: 0.3986\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.8389 - accuracy: 0.3471 - val_loss: 1.7564 - val_accuracy: 0.3993\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.8358 - accuracy: 0.3490 - val_loss: 1.7538 - val_accuracy: 0.4011\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.8330 - accuracy: 0.3456 - val_loss: 1.7513 - val_accuracy: 0.3996\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.8328 - accuracy: 0.3474 - val_loss: 1.7490 - val_accuracy: 0.4008\n",
      "Epoch 94/100\n",
      "132/313 [===========>..................] - ETA: 0s - loss: 1.8362 - accuracy: 0.3450"
     ]
    }
   ],
   "source": [
    "(X,y), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "m = Machine(X,y,nb_classes=10)\n",
    "m.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
